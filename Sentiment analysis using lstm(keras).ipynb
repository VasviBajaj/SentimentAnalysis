{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "75e37e5abb691df18a94631fc63429452b8e3650"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajat\\Anaconda3\\envs\\pyt36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../input/train.tsv',  sep=\"\\t\")\n",
    "test = pd.read_csv('../input/test.tsv',  sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0261c62c3b24f293de41db76dca8f78caea96c45"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79c59246fcf9702a5b4b3dea42f88af5cbed8449"
   },
   "outputs": [],
   "source": [
    "train['Phrase'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44be519fad02c4b21187bfbf388c42cdead077ce"
   },
   "outputs": [],
   "source": [
    "train['Phrase'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6770a64f795c74ae6808fbae1ad0ddc188181bda"
   },
   "outputs": [],
   "source": [
    "train['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de77d1b021b8b009941da1f5eba9271fc7b91d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_data(train, test, max_features, maxlen):\n",
    "    \"\"\"\n",
    "    Convert data to proper format.\n",
    "    1) Shuffle\n",
    "    2) Lowercase\n",
    "    3) Sentiments to Categorical\n",
    "    4) Tokenize and Fit\n",
    "    5) Convert to sequence (format accepted by the network)\n",
    "    6) Pad\n",
    "    7) Voila!\n",
    "    \"\"\"\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.utils import to_categorical\n",
    "    \n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "    train['Phrase'] = train['Phrase'].apply(lambda x: x.lower())\n",
    "    test['Phrase'] = test['Phrase'].apply(lambda x: x.lower())\n",
    "\n",
    "    X = train['Phrase']\n",
    "    test_X = test['Phrase']\n",
    "    Y = to_categorical(train['Sentiment'].values)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(X))\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=maxlen)\n",
    "    test_X = tokenizer.texts_to_sequences(test_X)\n",
    "    test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "    return X, Y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cf2b30b50701c41c7da82b285df5edf597647cc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 125\n",
    "max_features = 10000\n",
    "\n",
    "X, Y, test_X = format_data(train, test, max_features, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87a8e790a08d921810dc2fe5c38740a905e453d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "866799ad61088c89baecb72ff2a0a37bde4a3eaf"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Embedding(max_features,100,mask_zero=True))\n",
    "model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
    "model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb5e9a193d224c189a7eccfdb39c20668226dce3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c4aee226faf679bc6663d09df69e7dccd169a3a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7a864588f97c857b121c54de85fe2a9e4c16a00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('lstm_model2.h5')\n",
    "sub = pd.read_csv('sampleSubmission.csv')\n",
    "\n",
    "sub['Sentiment'] = model.predict_classes(test_X, batch_size=batch_size, verbose=1)\n",
    "sub.to_csv('sub_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
